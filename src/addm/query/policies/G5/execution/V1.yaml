# G5_execution_V1: Base Execution Quality Assessment
# V1 = Base: Simple per-instance reasoning, basic thresholds
# Owner perspective: Evaluating order accuracy and promise keeping

policy_id: G5_execution_V1
version: "1.0"

# === OVERVIEW (generates Overview section) ===
overview:
  title: "Execution Quality Assessment"

  purpose: |
    Help assess how well this restaurant executes orders and keeps promises using reviews as evidence.
    This is from the perspective of a business owner diagnosing operational issues.
    Assign a label: Needs Improvement, Satisfactory, or Excellent.

  incident_definition: |
    Consider reviews that mention any of the following:
    - order accuracy (correct items, modifications)
    - promises made and kept
    - how issues were resolved
    - menu accuracy and descriptions

    Reviews that only discuss ambiance without mentioning order execution carry less weight.

# === NORMATIVE (generates Definitions + Verdict Rules) ===
normative:
  # Terms -> auto-generates Definitions section
  terms:
    - ref: "shared:ACCOUNT_TYPE"
    - ref: "execution:ORDER_ACCURACY"
    - ref: "execution:MODIFICATION_HANDLING"
    - ref: "execution:PROMISE_KEPT"
    - ref: "execution:ISSUE_RESOLUTION"

  # Decision policy -> generates Verdict Rules section
  decision:
    verdicts: ["Needs Improvement", "Satisfactory", "Excellent"]
    ordered: true  # Higher = better performance

    rules:
      - verdict: "Excellent"
        label: "EXCELLENT"
        logic: ANY
        conditions:
          - text: "190 or more reviews report perfect order accuracy"
            type: count_threshold
            filter:
              order_accuracy: perfect
            min_count: 190
            min_count_by_k:
              25: 24
              50: 48
              100: 95
          - text: "100 or more reviews report successful modification handling"
            type: count_threshold
            filter:
              modification_handling: successful
            min_count: 100
            min_count_by_k:
              25: 15
              50: 28
              100: 55
          - text: "180 or more reviews report promises kept"
            type: count_threshold
            filter:
              promise_kept: kept
            min_count: 180
            min_count_by_k:
              25: 23
              50: 45
              100: 90

      - verdict: "Needs Improvement"
        label: "NEEDS_IMPROVEMENT"
        precondition: "Excellent does not apply"
        logic: ANY
        conditions:
          - text: "35 or more reviews report significant or multiple order errors"
            type: count_threshold
            filter:
              order_accuracy: [multiple_errors, significant_error]
            min_count: 35
            min_count_by_k:
              25: 8
              50: 14
              100: 24
          - text: "120 or more reviews report modifications being ignored"
            type: count_threshold
            filter:
              modification_handling: ignored
            min_count: 120
            min_count_by_k:
              25: 18
              50: 34
              100: 68
          - text: "45 or more reviews report broken promises"
            type: count_threshold
            filter:
              promise_kept: broken
            min_count: 45
            min_count_by_k:
              25: 10
              50: 16
              100: 28

      - verdict: "Satisfactory"
        label: "SATISFACTORY"
        default: true
        especially_when:
          - "Orders generally correct"
          - "Occasional issues handled adequately"
          - "Most promises kept"

  # Output format
  output:
    verdict:
      type: enum
      values: ["Needs Improvement", "Satisfactory", "Excellent"]
      required: true

    evidence:
      type: array
      items:
        review_id: string
        quote: string
      description: "Relevant quotes supporting the verdict"

    justification:
      type: string
      required: true
      description: "Explain how the evidence was used to arrive at the final verdict"

    confidence:
      type: enum
      values: ["low", "medium", "high"]
      note: "Based on evidence volume: low=1-2, medium=3-5, high=6+ relevant reviews"

    other_notes:
      type: string
      optional: true
      description: "Any other relevant observations or caveats"
